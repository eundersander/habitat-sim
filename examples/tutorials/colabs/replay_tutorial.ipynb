{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://raw.githubusercontent.com/facebookresearch/habitat-sim/master/examples/colab_utils/colab_install.sh | NIGHTLY=true bash -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# @title Setup code { display-mode: \"form\" }\n",
    "# @markdown (double click to show code)\n",
    "%cd /content/habitat-sim\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import git\n",
    "import magnum as mn\n",
    "import numpy as np\n",
    "\n",
    "import habitat_sim\n",
    "from habitat_sim import gfx_replay_utils\n",
    "from habitat_sim.utils import viz_utils as vut\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/bin/ffmpeg\"\n",
    "\n",
    "repo = git.Repo(\".\", search_parent_directories=True)\n",
    "dir_path = repo.working_tree_dir\n",
    "%cd $dir_path\n",
    "data_path = os.path.join(dir_path, \"data\")\n",
    "output_path = os.path.join(dir_path, \"examples/tutorials/replay_tutorial_output/\")\n",
    "\n",
    "\n",
    "def remove_all_objects(sim):\n",
    "    for id_ in sim.get_existing_object_ids():\n",
    "        sim.remove_object(id_)\n",
    "\n",
    "\n",
    "def make_configuration():\n",
    "    # simulator configuration\n",
    "    backend_cfg = habitat_sim.SimulatorConfiguration()\n",
    "    backend_cfg.scene_id = os.path.join(\n",
    "        data_path, \"scene_datasets/habitat-test-scenes/apartment_1.glb\"\n",
    "    )\n",
    "    assert os.path.exists(backend_cfg.scene_id)\n",
    "    backend_cfg.enable_physics = True\n",
    "\n",
    "    # Enable gfx replay save. See also our call to sim.gfx_replay_manager.save_keyframe()\n",
    "    # below.\n",
    "    backend_cfg.enable_gfx_replay_save = True\n",
    "\n",
    "    # sensor configuration\n",
    "    sensor_specs = []\n",
    "    sensor_spec = habitat_sim.SensorSpec()\n",
    "    sensor_spec.uuid = \"rgba_camera_1stperson\"\n",
    "    sensor_spec.sensor_type = habitat_sim.SensorType.COLOR\n",
    "    sensor_spec.resolution = [544, 720]\n",
    "    sensor_specs.append(sensor_spec)\n",
    "\n",
    "    # agent configuration\n",
    "    agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "    agent_cfg.sensor_specifications = sensor_specs\n",
    "\n",
    "    return habitat_sim.Configuration(backend_cfg, [agent_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# @title Helper function to move our agent, step physics, and showcase the replay recording API.\n",
    "\n",
    "\n",
    "def simulate_with_moving_agent(\n",
    "    sim,\n",
    "    duration=1.0,\n",
    "    agent_vel=np.array([0, 0, 0]),\n",
    "    look_rotation_vel=0.0,\n",
    "    get_frames=True,\n",
    "):\n",
    "    sensor_node = sim._sensors[\"rgba_camera_1stperson\"]._sensor_object.object\n",
    "    agent_node = sim.get_agent(0).body.object\n",
    "\n",
    "    # simulate dt seconds at 60Hz to the nearest fixed timestep\n",
    "    time_step = 1.0 / 60.0\n",
    "\n",
    "    rotation_x = mn.Quaternion.rotation(\n",
    "        mn.Deg(look_rotation_vel) * time_step, mn.Vector3(1.0, 0, 0)\n",
    "    )\n",
    "\n",
    "    print(\"Simulating \" + str(duration) + \" world seconds.\")\n",
    "    observations = []\n",
    "    start_time = sim.get_world_time()\n",
    "    while sim.get_world_time() < start_time + duration:\n",
    "\n",
    "        # move agent\n",
    "        agent_node.translation += agent_vel * time_step\n",
    "\n",
    "        # rotate sensor\n",
    "        sensor_node.rotation *= rotation_x\n",
    "\n",
    "        # Add user transforms for the agent and sensor. We'll use these later during\n",
    "        # replay playback.\n",
    "        gfx_replay_utils.add_node_user_transform(sim, agent_node, \"agent\")\n",
    "        gfx_replay_utils.add_node_user_transform(sim, sensor_node, \"sensor\")\n",
    "\n",
    "        sim.step_physics(time_step)\n",
    "\n",
    "        # save a replay keyframe after every physics step\n",
    "        sim.gfx_replay_manager.save_keyframe()\n",
    "\n",
    "        if get_frames:\n",
    "            observations.append(sim.get_sensor_observations())\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title More setup\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--no-show-video\", dest=\"show_video\", action=\"store_false\")\n",
    "    parser.add_argument(\"--no-make-video\", dest=\"make_video\", action=\"store_false\")\n",
    "    parser.set_defaults(show_video=True, make_video=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    show_video = args.show_video\n",
    "    make_video = args.make_video\n",
    "    if make_video and not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    cfg = make_configuration()\n",
    "    sim = None\n",
    "    random.seed(0)\n",
    "    replay_filepaths = []\n",
    "    num_episodes = 1\n",
    "\n",
    "    for episode_index in range(num_episodes):\n",
    "        episodeName = \"episode{}\".format(episode_index)\n",
    "        replay_filepath = output_path + episodeName + \".json\"\n",
    "        replay_filepaths.append(replay_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # @title Run three episodes. Save videos and replays.\n",
    "\n",
    "    for episode_index in range(num_episodes):\n",
    "\n",
    "        if not sim:\n",
    "            sim = habitat_sim.Simulator(cfg)\n",
    "        else:\n",
    "            sim.reconfigure(cfg)\n",
    "\n",
    "        agent_state = habitat_sim.AgentState()\n",
    "        agent = sim.initialize_agent(0, agent_state)\n",
    "\n",
    "        agent_node = sim.get_agent(0).body.object\n",
    "        sensor_node = sim._sensors[\"rgba_camera_1stperson\"]._sensor_object.object\n",
    "\n",
    "        # initial agent transform\n",
    "        agent_node.translation = [-0.15, -1.5, 1.0]\n",
    "        agent_node.rotation = mn.Quaternion.rotation(\n",
    "            mn.Deg(-75), mn.Vector3(0.0, 1.0, 0)\n",
    "        )\n",
    "\n",
    "        # initial sensor local transform (relative to agent)\n",
    "        sensor_node.translation = [0.0, 0.6, 0.0]\n",
    "        sensor_node.rotation = mn.Quaternion.rotation(\n",
    "            mn.Deg(-15), mn.Vector3(1.0, 0.0, 0)\n",
    "        )\n",
    "\n",
    "        observations = []\n",
    "\n",
    "        # simulate with empty scene\n",
    "        observations += simulate_with_moving_agent(\n",
    "            sim,\n",
    "            duration=1.0,\n",
    "            agent_vel=np.array([0.5, 0.0, 0.0]),\n",
    "            look_rotation_vel=25.0,\n",
    "            get_frames=make_video,\n",
    "        )\n",
    "\n",
    "        obj_templates_mgr = sim.get_object_template_manager()\n",
    "\n",
    "        obj_templates_mgr.load_configs(str(os.path.join(data_path, \"objects\")))\n",
    "        chefcan_template_handle = obj_templates_mgr.get_template_handles(\n",
    "            \"data/objects/chefcan\"\n",
    "        )[0]\n",
    "\n",
    "        y_dist = 0.1\n",
    "\n",
    "        # drop some dynamic objects\n",
    "        id_1 = sim.add_object_by_handle(chefcan_template_handle)\n",
    "        sim.set_translation(\n",
    "            np.array([2.4, -0.64 + random.uniform(-y_dist, y_dist), 0]), id_1\n",
    "        )\n",
    "        id_2 = sim.add_object_by_handle(chefcan_template_handle)\n",
    "        sim.set_translation(\n",
    "            np.array([2.4, -0.64 + random.uniform(-y_dist, y_dist), 0.28]), id_2\n",
    "        )\n",
    "        id_3 = sim.add_object_by_handle(chefcan_template_handle)\n",
    "        sim.set_translation(\n",
    "            np.array([2.4, -0.64 + random.uniform(-y_dist, y_dist), -0.28]), id_3\n",
    "        )\n",
    "\n",
    "        # simulate\n",
    "        observations += simulate_with_moving_agent(\n",
    "            sim,\n",
    "            duration=2.0,\n",
    "            agent_vel=np.array([0.0, 0.0, -0.4]),\n",
    "            look_rotation_vel=-5.0,\n",
    "            get_frames=make_video,\n",
    "        )\n",
    "\n",
    "        # remove some objects\n",
    "        sim.remove_object(id_1)\n",
    "        sim.remove_object(id_2)\n",
    "\n",
    "        observations += simulate_with_moving_agent(\n",
    "            sim,\n",
    "            duration=2.0,\n",
    "            agent_vel=np.array([0.4, 0.0, 0.0]),\n",
    "            look_rotation_vel=-10.0,\n",
    "            get_frames=make_video,\n",
    "        )\n",
    "\n",
    "        episodeName = \"episode{}\".format(episode_index)\n",
    "\n",
    "        if make_video:\n",
    "            vut.make_video(\n",
    "                observations,\n",
    "                \"rgba_camera_1stperson\",\n",
    "                \"color\",\n",
    "                output_path + episodeName,\n",
    "                open_vid=show_video,\n",
    "            )\n",
    "\n",
    "        # save a replay at the end of an episode\n",
    "        sim.gfx_replay_manager.write_saved_keyframes_to_file(\n",
    "            replay_filepaths[episode_index]\n",
    "        )\n",
    "\n",
    "        remove_all_objects(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # @title Reconfigure simulator for replay playback.\n",
    "    if True:\n",
    "\n",
    "        # use same agents/sensors from earlier, with different backend config\n",
    "        playback_cfg = habitat_sim.Configuration(\n",
    "            # gfx_replay_utils.make_backend_configuration_for_playback(need_separate_semantic_scene_graph=True),\n",
    "            gfx_replay_utils.make_backend_configuration_for_playback(\n",
    "                need_separate_semantic_scene_graph=False\n",
    "            ),\n",
    "            cfg.agents,\n",
    "        )\n",
    "\n",
    "        if not sim:\n",
    "            sim = habitat_sim.Simulator(playback_cfg)\n",
    "        else:\n",
    "            sim.reconfigure(playback_cfg)\n",
    "\n",
    "        agent_state = habitat_sim.AgentState()\n",
    "        sim.initialize_agent(0, agent_state)\n",
    "\n",
    "        agent_node = sim.get_agent(0).body.object\n",
    "        sensor_node = sim._sensors[\"rgba_camera_1stperson\"]._sensor_object.object\n",
    "\n",
    "        # For replay playback, we place a dummy agent at the origin and then transform\n",
    "        # the sensor using the \"sensor\" user transform stored in the replay.\n",
    "        # In the future, Habitat will offer a cleaner way to play replays without an agent.\n",
    "        agent_node.translation = [0.0, 0.0, 0.0]\n",
    "        agent_node.rotation = mn.Quaternion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # @title load replays\n",
    "\n",
    "        players = []\n",
    "        for filepath in replay_filepaths:\n",
    "            player = sim.gfx_replay_manager.read_keyframes_from_file(filepath)\n",
    "            assert player\n",
    "            players.append(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # @title play replay #0\n",
    "\n",
    "        observations = []\n",
    "        print(\"play replay #0...\")\n",
    "        for frame in range(players[0].get_num_keyframes()):\n",
    "            players[0].set_keyframe_index(frame)\n",
    "\n",
    "            # todo: add comment\n",
    "            (sensor_node.translation, sensor_node.rotation) = player.get_user_transform(\n",
    "                \"sensor\"\n",
    "            )\n",
    "\n",
    "            observations.append(sim.get_sensor_observations())\n",
    "\n",
    "        if make_video:\n",
    "            vut.make_video(\n",
    "                observations,\n",
    "                \"rgba_camera_1stperson\",\n",
    "                \"color\",\n",
    "                output_path + \"replay_playback1\",\n",
    "                open_vid=show_video,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # @title play in reverse at 3x\n",
    "\n",
    "        observations = []\n",
    "        print(\"play in reverse at 3x...\")\n",
    "        for frame in range(players[0].get_num_keyframes() - 2, -1, -3):\n",
    "            players[0].set_keyframe_index(frame)\n",
    "            (sensor_node.translation, sensor_node.rotation) = player.get_user_transform(\n",
    "                \"sensor\"\n",
    "            )\n",
    "            observations.append(sim.get_sensor_observations())\n",
    "\n",
    "        if make_video:\n",
    "            vut.make_video(\n",
    "                observations,\n",
    "                \"rgba_camera_1stperson\",\n",
    "                \"color\",\n",
    "                output_path + \"replay_playback2\",\n",
    "                open_vid=show_video,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # @title play from a different camera view, with agent visualization\n",
    "\n",
    "        observations = []\n",
    "        print(\"play from a different camera view, with agent visualization...\")\n",
    "\n",
    "        # place a third-person camera\n",
    "        sensor_node.translation = [-1.1, -0.9, -0.2]\n",
    "        sensor_node.rotation = mn.Quaternion.rotation(\n",
    "            mn.Deg(-115), mn.Vector3(0.0, 1.0, 0)\n",
    "        )\n",
    "\n",
    "        prim_attr_mgr = sim.get_asset_template_manager()\n",
    "\n",
    "        # visualize the recorded agent transform as a cylinder\n",
    "        agent_viz_handle = prim_attr_mgr.get_template_handles(\"cylinderSolid\")[0]\n",
    "        agent_viz_id = sim.add_object_by_handle(agent_viz_handle)\n",
    "        sim.set_object_motion_type(\n",
    "            habitat_sim.physics.MotionType.KINEMATIC, agent_viz_id\n",
    "        )\n",
    "        sim.set_object_is_collidable(False, agent_viz_id)\n",
    "\n",
    "        # visualize the recorded sensor transform as a cube\n",
    "        sensor_viz_handle = prim_attr_mgr.get_template_handles(\"cubeSolid\")[0]\n",
    "        sensor_viz_id = sim.add_object_by_handle(sensor_viz_handle)\n",
    "        sim.set_object_motion_type(\n",
    "            habitat_sim.physics.MotionType.KINEMATIC, sensor_viz_id\n",
    "        )\n",
    "        sim.set_object_is_collidable(False, sensor_viz_id)\n",
    "\n",
    "        for frame in range(players[0].get_num_keyframes()):\n",
    "            players[0].set_keyframe_index(frame)\n",
    "\n",
    "            (agent_translation, agent_rotation) = players[0].get_user_transform(\"agent\")\n",
    "            sim.set_translation(agent_translation, agent_viz_id)\n",
    "            sim.set_rotation(agent_rotation, agent_viz_id)\n",
    "\n",
    "            (sensor_translation, sensor_rotation) = players[0].get_user_transform(\n",
    "                \"sensor\"\n",
    "            )\n",
    "            sim.set_translation(sensor_translation, sensor_viz_id)\n",
    "            sim.set_rotation(sensor_rotation, sensor_viz_id)\n",
    "\n",
    "            observations.append(sim.get_sensor_observations())\n",
    "\n",
    "        if make_video:\n",
    "            vut.make_video(\n",
    "                observations,\n",
    "                \"rgba_camera_1stperson\",\n",
    "                \"color\",\n",
    "                output_path + \"replay_playback3\",\n",
    "                open_vid=show_video,\n",
    "            )\n",
    "\n",
    "        sim.remove_object(agent_viz_id)\n",
    "\n",
    "        # print(\"play all {} replays together...\".format(num_episodes))\n",
    "        # for frame in range(players[0].get_num_keyframes()):\n",
    "        #     for player in players:\n",
    "        #         player.set_keyframe_index(frame)\n",
    "        #     gfx_replay_utils.set_agent_from_user_transform(players[0], sim)\n",
    "        #     observations.append(sim.get_sensor_observations())\n",
    "\n",
    "        # if make_video:\n",
    "        #     vut.make_video(\n",
    "        #         observations,\n",
    "        #         \"rgba_camera_1stperson\",\n",
    "        #         \"color\",\n",
    "        #         output_path + \"replay_playback\",\n",
    "        #         open_vid=show_video,\n",
    "        #     )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Replay Tutorial",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "nb_python//py:percent,colabs//ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
